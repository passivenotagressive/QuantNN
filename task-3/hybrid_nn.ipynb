{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T12:38:07.474778Z",
     "start_time": "2023-07-05T12:38:07.447555Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pennylane in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.39.0)\n",
      "Requirement already satisfied: numpy<2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (1.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (3.4.2)\n",
      "Requirement already satisfied: rustworkx>=0.14.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (0.15.1)\n",
      "Requirement already satisfied: autograd in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (1.7.0)\n",
      "Requirement already satisfied: toml in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: autoray>=0.6.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (0.7.0)\n",
      "Requirement already satisfied: cachetools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (5.5.0)\n",
      "Requirement already satisfied: pennylane-lightning>=0.39 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (0.39.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (4.12.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pennylane) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pennylane) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pennylane) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pennylane) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pennylane) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pennylane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a qnode in `pennylane`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T13:01:56.756178Z",
     "start_time": "2023-07-05T13:01:56.742650Z"
    }
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "n_qubits = 8\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    # Embedding\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "\n",
    "    # Entanglement\n",
    "    for j in range(weights.shape[0]):\n",
    "        for i in range(weights.shape[1]):\n",
    "            qml.RY(weights[j][i], wires=i)\n",
    "\n",
    "        for i in range(weights.shape[1] - 1):\n",
    "            qml.CNOT(wires=[i, i + 1])\n",
    "\n",
    "        qml.CNOT(wires=[weights.shape[1] - 1, 0])\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(weights.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(qml.draw(qnode)(inputs=np.random.rand(4), weights=np.random.randn(4, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the QNode to be successfully converted to a layer in `torch.nn`, we need to provide the details of the shape of each trainable weight for them to be initialized. The weight_shapes dictionary maps from the argument names of the QNode to corresponding shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T13:01:57.072270Z",
     "start_time": "2023-07-05T13:01:57.066759Z"
    }
   },
   "outputs": [],
   "source": [
    "n_layers = 6\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that `weight_shapes` is defined, it is easy to then convert the QNode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T13:01:57.492565Z",
     "start_time": "2023-07-05T13:01:57.484528Z"
    }
   },
   "outputs": [],
   "source": [
    "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this done, the QNode can now be treated just like any other torch.nn layer and we can proceed using the familiar Torch workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a hybrid model\n",
    "Since our text is already embedded, our hybrid model will consist of:\n",
    "\n",
    "1) two fully connected classical layers: 768 -> 128 and 128 -> 8\n",
    "2) an 8-qubit QNode converted into a layer\n",
    "3) a fully connected classical layer: 8 -> 1\n",
    "4) a sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T13:01:58.062543Z",
     "start_time": "2023-07-05T13:01:58.058570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (1): Linear(in_features=128, out_features=8, bias=True)\n",
       "  (2): <Quantum Torch Layer: func=qnode>\n",
       "  (3): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (4): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clayer_1 = torch.nn.Linear(768, 128)\n",
    "clayer_2 = torch.nn.Linear(128, n_qubits)\n",
    "relayer_1 = torch.nn.LeakyReLU(0.2)\n",
    "clayer_3 = torch.nn.Linear(n_qubits, 1)\n",
    "softmax = torch.nn.Sigmoid()\n",
    "layers = [clayer_1, clayer_2, qlayer, clayer_3, softmax]\n",
    "model = torch.nn.Sequential(*layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "We can now train our hybrid model on the classification dataset using the usual Torch approach. Weâ€™ll use the standard `SGD` optimizer and the mean absolute error loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T13:01:59.618146Z",
     "start_time": "2023-07-05T13:01:59.615742Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=0.2)\n",
    "loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T13:02:47.609072Z",
     "start_time": "2023-07-05T13:02:43.578944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7012\\795876464.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X = torch.load(open(\"data/X.pt\", 'rb'))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7012\\795876464.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y = torch.load(open(\"data/y.pt\", 'rb'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 1: 0.0289\n",
      "Validation accuracy: 45.24%\n",
      "Average loss over epoch 2: 0.0280\n",
      "Validation accuracy: 45.24%\n",
      "Average loss over epoch 3: 0.0269\n",
      "Validation accuracy: 45.24%\n",
      "Average loss over epoch 4: 0.0263\n",
      "Validation accuracy: 45.24%\n",
      "Average loss over epoch 5: 0.0252\n",
      "Validation accuracy: 45.24%\n",
      "Average loss over epoch 6: 0.0245\n",
      "Validation accuracy: 45.24%\n",
      "Average loss over epoch 7: 0.0240\n",
      "Validation accuracy: 52.38%\n",
      "Average loss over epoch 8: 0.0236\n",
      "Validation accuracy: 71.43%\n",
      "Average loss over epoch 9: 0.0227\n",
      "Validation accuracy: 66.67%\n",
      "Average loss over epoch 10: 0.0220\n",
      "Validation accuracy: 73.81%\n",
      "Average loss over epoch 11: 0.0208\n",
      "Validation accuracy: 73.81%\n",
      "Average loss over epoch 12: 0.0212\n",
      "Validation accuracy: 85.71%\n",
      "Average loss over epoch 13: 0.0197\n",
      "Validation accuracy: 100.00%\n",
      "Average loss over epoch 14: 0.0201\n",
      "Validation accuracy: 45.24%\n",
      "Average loss over epoch 15: 0.0221\n",
      "Validation accuracy: 80.95%\n",
      "Average loss over epoch 16: 0.0184\n",
      "Validation accuracy: 85.71%\n",
      "Average loss over epoch 17: 0.0157\n",
      "Validation accuracy: 90.48%\n",
      "Average loss over epoch 18: 0.0179\n",
      "Validation accuracy: 90.48%\n",
      "Average loss over epoch 19: 0.0222\n",
      "Validation accuracy: 64.29%\n",
      "Average loss over epoch 20: 0.0175\n",
      "Validation accuracy: 64.29%\n"
     ]
    }
   ],
   "source": [
    "X = torch.load(open(\"data/X.pt\", 'rb'))\n",
    "y = torch.load(open(\"data/y.pt\", 'rb'))\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "data = list(zip(X, y))\n",
    "data_train, data_test = torch.utils.data.random_split(data, [0.8, 0.2])\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    data_train, batch_size=20, shuffle=True, drop_last=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(dataset=data_test, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    for xs, ys in data_loader:\n",
    "        opt.zero_grad()\n",
    "        loss_evaluated = loss(model(xs).squeeze(), ys.float())\n",
    "        loss_evaluated.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss_evaluated\n",
    "\n",
    "    avg_loss = running_loss / len(y)\n",
    "    print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n",
    "\n",
    "    correct = 0\n",
    "    for xt, yt in test_loader:\n",
    "        # print(model(xt), yt)\n",
    "        correct += (model(xt) >= 0.5) == yt\n",
    "    accuracy = correct / len(test_loader)\n",
    "    accuracies.append(accuracy.item())\n",
    "    print(f\"Validation accuracy: {accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4523809552192688, 0.4523809552192688, 0.4523809552192688, 0.4523809552192688, 0.4523809552192688, 0.4523809552192688, 0.523809552192688, 0.7142857313156128, 0.6666666865348816, 0.738095223903656, 0.738095223903656, 0.8571428656578064, 1.0, 0.4523809552192688, 0.8095238208770752, 0.8571428656578064, 0.9047619104385376, 0.9047619104385376, 0.6428571343421936, 0.6428571343421936]\n",
      "Accuracy: 64.29%\n"
     ]
    }
   ],
   "source": [
    "print(accuracies[:20])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=data_test, shuffle=False)\n",
    "correct = 0\n",
    "for xt, yt in test_loader:\n",
    "    correct += (model(xt) >= 0.5) == yt\n",
    "accuracy = correct / len(test_loader)\n",
    "print(f\"Accuracy: {accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), open(\"new_good_quantum.pt\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model and run it on the new test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7012\\2178871295.py:1: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  model.load_state_dict(torch.load(\"pretrained_quantum\\good_quantum_100.pt\", weights_only=True))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7012\\2178871295.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X = torch.load(open(\"data/X_test.pt\", 'rb'))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_7012\\2178871295.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  y = torch.load(open(\"data/y_test.pt\", 'rb'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.39%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"pretrained_quantum\\good_quantum_100.pt\", weights_only=True))\n",
    "\n",
    "X = torch.load(open(\"data/X_test.pt\", 'rb'))\n",
    "y = torch.load(open(\"data/y_test.pt\", 'rb'))\n",
    "\n",
    "data = list(zip(X, y))\n",
    "test50_loader = torch.utils.data.DataLoader(\n",
    "    data, shuffle=False, drop_last=False\n",
    ")\n",
    "\n",
    "correct = 0\n",
    "for xt, yt in test50_loader:\n",
    "    correct += (model(xt) >= 0.5) == yt\n",
    "accuracy = correct / len(test50_loader)\n",
    "print(f\"Accuracy: {accuracy.item() * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
